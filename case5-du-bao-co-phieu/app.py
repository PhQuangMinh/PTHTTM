import os
import re
from typing import List, Optional, Tuple

import numpy as np
import pandas as pd
import joblib
import streamlit as st
import plotly.graph_objects as go
import tensorflow as tf

# C·∫•u h√¨nh port mong mu·ªën (8505) n·∫øu ch·∫°y b·∫±ng `streamlit run`
os.environ.setdefault("STREAMLIT_SERVER_PORT", "8505")

# =============================
# Paths and constants
# =============================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, "data")
SCALER_DIR = os.path.join(BASE_DIR, "scaler")
MODELS_DIR = os.path.join(BASE_DIR, "models")

TICKERS = ["BID", "BVH", "CTG"]
MODEL_TYPES = ["LSTM", "RNN"]

DATE_COLS = [
    "date",
    "time",
    "datetime",
    "ngay",
    "timestamp",
    "Date",
    "Datetime",
    "DTYYYYMMDD",  # ph·ªï bi·∫øn trong d·ªØ li·ªáu VNDirect
]
PRICE_COLS = [
    "close",
    "adj close",
    "close_price",
    "close price",
    "gia dong cua",
    "Close",
    "closeprice",
]


# =============================
# Utilities
# =============================
def detect_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:
    """
    T√¨m c·ªôt theo t√™n ·ª©ng vi√™n, cho ph√©p d·ªØ li·ªáu c√≥ k√Ω t·ª± l·∫° nh∆∞ <> , kho·∫£ng tr·∫Øng...
    So kh·ªõp d·ª±a tr√™n t√™n ƒë√£ chu·∫©n h√≥a (ch·ªâ c√≤n a-z0-9).
    """
    def norm(s: str) -> str:
        return re.sub(r"[^a-z0-9]", "", s.lower())

    normalized_to_original = {norm(col): col for col in df.columns}

    # Th·ª≠ kh·ªõp ch√≠nh x√°c theo normalize
    for cand in candidates:
        cand_n = norm(cand)
        if cand_n in normalized_to_original:
            return normalized_to_original[cand_n]

    # Fallback: t√¨m c·ªôt c√≥ ch·ª©a t·ª´ kh√≥a ·ª©ng vi√™n (v√≠ d·ª•: 'date' n·∫±m trong 'dtyyyymmdd')
    for cand in candidates:
        cand_n = norm(cand)
        for col_n, col in normalized_to_original.items():
            if cand_n in col_n or col_n in cand_n:
                return col

    return None


def load_ticker_data(ticker: str) -> Tuple[pd.Series, pd.Series]:
    """
    Load CSV for a ticker and return (dates, close_prices).
    """
    csv_path = os.path.join(DATA_DIR, f"{ticker}.csv")
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {csv_path}")

    df = pd.read_csv(csv_path)
    date_col = detect_col(df, DATE_COLS)
    price_col = detect_col(df, PRICE_COLS)
    if date_col is None or price_col is None:
        raise ValueError("Kh√¥ng ph√°t hi·ªán c·ªôt th·ªùi gian/gi√° trong d·ªØ li·ªáu")

    # Chu·∫©n h√≥a c·ªôt ng√†y: n·∫øu l√† s·ªë 8 ch·ªØ s·ªë (YYYYMMDD) th√¨ parse theo ƒë·ªãnh d·∫°ng
    date_series = df[date_col]
    if pd.api.types.is_numeric_dtype(date_series) or date_series.astype(str).str.fullmatch(r"\d{8}").all():
        df[date_col] = pd.to_datetime(date_series.astype(str), format="%Y%m%d", errors="coerce")
    else:
        df[date_col] = pd.to_datetime(date_series, errors="coerce")

    df = df.dropna(subset=[date_col]).sort_values(date_col)
    df[price_col] = pd.to_numeric(df[price_col], errors="coerce")
    df = df.dropna(subset=[price_col])
    return df[date_col].reset_index(drop=True), df[price_col].reset_index(drop=True)


def load_scaler(ticker: str):
    pkl = os.path.join(SCALER_DIR, f"{ticker}_scaler.pkl")
    if os.path.exists(pkl):
        return joblib.load(pkl)
    # fallback if not saved
    from sklearn.preprocessing import MinMaxScaler
    return MinMaxScaler((0, 1))


def load_model(ticker: str, model_type: str, prefer_best: bool = True):
    mt = "lstm" if model_type.upper() == "LSTM" else "rnn"
    best = os.path.join(MODELS_DIR, f"{ticker}_{mt}_best.keras")
    final = os.path.join(MODELS_DIR, f"{ticker}_{mt}_final.keras")
    ckpt = best if (prefer_best and os.path.exists(best)) else (final if os.path.exists(final) else None)
    if ckpt is None:
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y model: {best} ho·∫∑c {final}")
    return tf.keras.models.load_model(ckpt), ckpt


def make_sequences(series_scaled: np.ndarray, lookback: int) -> Tuple[np.ndarray, np.ndarray]:
    """
    Given scaled series shaped (N, 1), build X (N-lookback, lookback, 1) and y (N-lookback, 1)
    for 1-step ahead forecasting.
    """
    X, y = [], []
    arr = series_scaled.reshape(-1, 1)
    for i in range(lookback, len(arr)):
        X.append(arr[i - lookback : i, 0])
        y.append(arr[i, 0])
    if not X:
        return np.empty((0, lookback, 1), dtype="float32"), np.empty((0, 1), dtype="float32")
    X = np.array(X, dtype="float32").reshape(-1, lookback, 1)
    y = np.array(y, dtype="float32").reshape(-1, 1)
    return X, y


def last_n_predictions(
    dates: pd.Series, prices: pd.Series, scaler, model, lookback: int, last_n: int = 30
) -> pd.DataFrame:
    """
    Build sliding 1-step predictions across the series, then return last_n rows with
    columns: ['date', 'actual', 'pred'].
    """
    values = prices.values.astype("float32").reshape(-1, 1)
    # Fit scaler if needed
    try:
        values_scaled = scaler.transform(values)
    except Exception:
        scaler.fit(values)
        values_scaled = scaler.transform(values)

    X, y = make_sequences(values_scaled, lookback)
    if len(X) == 0:
        return pd.DataFrame(columns=["date", "actual", "pred"])

    y_pred_scaled = model.predict(X, verbose=0)
    # Inverse scale
    try:
        y_true = scaler.inverse_transform(y)
        y_pred = scaler.inverse_transform(y_pred_scaled)
    except Exception:
        y_true, y_pred = y, y_pred_scaled

    target_dates = dates.iloc[lookback:].reset_index(drop=True)
    df = pd.DataFrame(
        {
            "date": target_dates[-last_n:],
            "actual": y_true.ravel()[-last_n:],
            "pred": y_pred.ravel()[-last_n:],
        }
    )
    return df


def mae_rmse(a: np.ndarray, b: np.ndarray) -> Tuple[float, float]:
    mae = float(np.mean(np.abs(a - b)))
    rmse = float(np.sqrt(np.mean((a - b) ** 2)))
    return mae, rmse


# =============================
# Streamlit UI
# =============================
st.set_page_config(page_title="D·ª± b√°o c·ªï phi·∫øu (Local)", page_icon="üìà", layout="wide")

# Simple white theme and readable text
st.markdown(
    """
    <style>
    .main, .stApp { background: #FFFFFF !important; color: #111111 !important; }
    section[data-testid="stSidebar"], section[data-testid="stSidebar"] * { background: #FFFFFF !important; color: #111111 !important; }
    .stMetric { background: #fff; color: #111111; }
    h1, h2, h3, h4, h5, h6, p, span, label, div { color: #111111 !important; }
    .stSelectbox div, .stSlider, .stSlider * { color: #111111 !important; }
    input, textarea, select, option { color: #111111 !important; background: #FFFFFF !important; }
    /* DataFrame b·∫£ng tr·∫Øng ch·ªØ ƒëen, vi·ªÅn x√°m ƒë·∫≠m */
    [data-testid="stDataFrame"] table { background: #FFFFFF !important; color: #111111 !important; }
    [data-testid="stDataFrame"] th, [data-testid="stDataFrame"] td { color: #111111 !important; border: 1px solid #222 !important; }
    [data-testid="stDataFrame"] thead { background: #f5f5f5 !important; color: #111111 !important; }
    </style>
    """,
    unsafe_allow_html=True,
)

st.title("üìà ·ª®ng d·ª•ng d·ª± b√°o c·ªï phi·∫øu (LSTM/RNN)")
st.caption("Ch·ªçn s√†n, ch·ªçn m√¥ h√¨nh v√† xem ƒë∆∞·ªùng d·ª± b√°o 30 ng√†y g·∫ßn nh·∫•t.")

with st.sidebar:
    st.header("C·∫•u h√¨nh")
    ticker = st.selectbox("Ch·ªçn s√†n/m√£", TICKERS, index=0)
    model_type = st.selectbox("Ch·ªçn m√¥ h√¨nh", MODEL_TYPES, index=0)
    lookback = st.slider("C·ª≠a s·ªï lookback", min_value=10, max_value=120, value=30, step=5)
    prefer_best = st.checkbox("∆Øu ti√™n model best (checkpoint)", value=True)
    st.info("Bi·ªÉu ƒë·ªì c·ªë ƒë·ªãnh hi·ªÉn th·ªã 30 ng√†y cu·ªëi c√πng trong d·ªØ li·ªáu.")

# Load data
try:
    dates, prices = load_ticker_data(ticker)
except Exception as e:
    st.error(f"L·ªói n·∫°p d·ªØ li·ªáu {ticker}: {e}")
    st.stop()

# Load scaler
try:
    scaler = load_scaler(ticker)
except Exception as e:
    st.warning(f"L·ªói n·∫°p scaler {ticker}: {e}. S·∫Ω fit tr·ª±c ti·∫øp tr√™n d·ªØ li·ªáu hi·ªán c√≥.")
    from sklearn.preprocessing import MinMaxScaler
    scaler = MinMaxScaler((0, 1))

# Load model
try:
    model, ckpt_path = load_model(ticker, model_type, prefer_best=prefer_best)
except Exception as e:
    st.error(f"L·ªói n·∫°p m√¥ h√¨nh {ticker} ({model_type}): {e}")
    st.stop()

# Inference for last 30 days
LAST_N = 30
df_plot = last_n_predictions(dates, prices, scaler, model, lookback=lookback, last_n=LAST_N)
if df_plot.empty:
    st.warning("D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ t·∫°o chu·ªói lookback. H√£y gi·∫£m lookback ho·∫∑c ki·ªÉm tra d·ªØ li·ªáu.")
    st.stop()

mae, rmse = mae_rmse(df_plot["actual"].values, df_plot["pred"].values)
# C·ªë ƒë·ªãnh tr·ª•c Y 0-100, tick m·ªói 10 ƒë·ªÉ zoom g·∫ßn v√† ƒë·ªìng nh·∫•t b√°o c√°o
y_range = [0, 100]

# Top KPIs
col1, col2, col3 = st.columns([1, 1, 2])
with col1:
    st.metric("MAE", f"{mae:.3f}")
with col2:
    st.metric("RMSE", f"{rmse:.3f}")
with col3:
    st.write(f"Model: `{os.path.basename(ckpt_path)}`")

# Line chart Actual vs Predict
fig = go.Figure()
fig.add_trace(
    go.Scatter(
        x=df_plot["date"],
        y=df_plot["actual"],
        mode="lines",
        name="Gi√° th·ª±c t·∫ø",
        line=dict(color="#2E86DE", width=2),
        hovertemplate="Ng√†y: %{x|%a %d %b %Y}<br>Gi√° th·ª±c t·∫ø: %{y:.2f}<extra></extra>",
    )
)
fig.add_trace(
    go.Scatter(
        x=df_plot["date"],
        y=df_plot["pred"],
        mode="lines",
        name="Gi√° d·ª± ƒëo√°n",
        line=dict(color="#54a0ff", width=2, shape="spline"),
        hovertemplate="Ng√†y: %{x|%a %d %b %Y}<br>Gi√° d·ª± ƒëo√°n: %{y:.2f}<extra></extra>",
    )
)
fig.update_layout(
    title=f"{ticker} - {model_type} | 30 ng√†y g·∫ßn nh·∫•t",
    xaxis_title="Ng√†y",
    yaxis_title="Gi√°",
    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0, font=dict(color="black")),
    margin=dict(l=10, r=10, t=60, b=10),
    template="simple_white",
    paper_bgcolor="#ffffff",
    plot_bgcolor="#ffffff",
    hovermode="x unified",
    font=dict(color="black")
)
fig.update_xaxes(
    showgrid=True,
    gridcolor="#eaeaea",
    tickformat="%a %d",
    tickformatstops=[
        dict(dtickrange=[None, 86400000 * 31], value="%a %d"),
        dict(dtickrange=[86400000 * 31, None], value="%b %Y"),
    ],
    tickfont=dict(color="black"),
    title_font=dict(color="black"),
    linecolor="black",
)
fig.update_yaxes(
    showgrid=True,
    gridcolor="#eaeaea",
    tickfont=dict(color="black"),
    title_font=dict(color="black"),
    linecolor="black",
    dtick=10,
    range=y_range,
)
st.plotly_chart(fig, use_container_width=True)

with st.expander("B·∫£ng d·ªØ li·ªáu 30 ng√†y cu·ªëi"):
    st.dataframe(df_plot, use_container_width=True)

st.caption(
    "M·∫πo: N·∫øu kh√¥ng th·∫•y ƒë∆∞·ªùng d·ª± b√°o, h√£y gi·∫£m lookback ho·∫∑c ƒë·∫£m b·∫£o scaler/model tr√πng v·ªõi thi·∫øt l·∫≠p khi train."
)

